{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Untitled1.ipynb","provenance":[{"file_id":"1SVaNXrmxmsl9MLHr1v7LzmqP3rH77fwP","timestamp":1623040867000}],"toc_visible":true,"authorship_tag":"ABX9TyPVezZHXS2UOscC86jYvO6p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"BeJWbzOvIbV6","executionInfo":{"status":"ok","timestamp":1623039306078,"user_tz":420,"elapsed":11,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}}},"source":["#import data into 2 data frames\n","#predict for next 300 days\n","#use a sentiment score on tweets like nlck"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhFsqMJZM9dE","executionInfo":{"status":"ok","timestamp":1623039306242,"user_tz":420,"elapsed":172,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}},"outputId":"1c387bee-aa6f-4c80-a2c3-aa5b2f0fa2a9"},"source":["#import libraries\n","import nltk #the natural language toolkit\n","import numpy as np #used for vector / matrix operations\n","import pandas as pd\n","from collections import Counter #used to count occurrences of n-grams\n","from nltk import pos_tag #used to generate part-of-speech (POS) tags\n","from nltk.tokenize import word_tokenize #used to split text into tokens\n","from sklearn.feature_extraction.text import TfidfVectorizer #used to generate TF-IDF vectors and build the vocabulary\n","from sklearn.linear_model import LogisticRegression #used to train logistic regression-based classifiers\n","from sklearn.model_selection import train_test_split #used to split the data into training and testing sets\n","nltk.download('averaged_perceptron_tagger') #needed to generate POS tags\n","nltk.download('punkt') #needed to tokenize text"],"execution_count":99,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"tbZ-tr2BNHNY","executionInfo":{"status":"ok","timestamp":1623039327364,"user_tz":420,"elapsed":21126,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}},"outputId":"574d81f4-1316-4b66-e047-de25dda34bc8"},"source":["#load data into dataframes\n","df = pd.read_excel('Project 02 - Data.xlsx', sheet_name=\"Numeric Data\")\n","df_Tweets = pd.read_excel('Project 02 - Data.xlsx', sheet_name=\"Tweets\")\n","df_lexicon = pd.read_excel('Lab Assignment 04 - Data.xlsx', sheet_name=1)\n","\n","#display the first few rows of product review data\n","df.head(10)"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>day</th>\n","      <th>open_price</th>\n","      <th>high_price</th>\n","      <th>low_price</th>\n","      <th>moving_average_5_day</th>\n","      <th>moving_average_10_day</th>\n","      <th>moving_average_50_day</th>\n","      <th>moving_average_200_day</th>\n","      <th>volume</th>\n","      <th>next_day_close_price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>44.55</td>\n","      <td>44.83</td>\n","      <td>44.32</td>\n","      <td>44.36</td>\n","      <td>43.82</td>\n","      <td>40.23</td>\n","      <td>42.25</td>\n","      <td>1500700</td>\n","      <td>44.83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>44.89</td>\n","      <td>45.12</td>\n","      <td>44.17</td>\n","      <td>44.37</td>\n","      <td>44.06</td>\n","      <td>40.32</td>\n","      <td>42.27</td>\n","      <td>2391800</td>\n","      <td>45.03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>45.04</td>\n","      <td>45.35</td>\n","      <td>44.84</td>\n","      <td>44.57</td>\n","      <td>44.21</td>\n","      <td>40.42</td>\n","      <td>42.27</td>\n","      <td>1723400</td>\n","      <td>44.97</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>45.02</td>\n","      <td>45.15</td>\n","      <td>44.70</td>\n","      <td>44.65</td>\n","      <td>44.40</td>\n","      <td>40.50</td>\n","      <td>42.28</td>\n","      <td>1490500</td>\n","      <td>44.91</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>44.75</td>\n","      <td>45.04</td>\n","      <td>44.65</td>\n","      <td>44.76</td>\n","      <td>44.58</td>\n","      <td>40.59</td>\n","      <td>42.28</td>\n","      <td>1349500</td>\n","      <td>45.31</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>45.04</td>\n","      <td>45.35</td>\n","      <td>44.53</td>\n","      <td>44.88</td>\n","      <td>44.62</td>\n","      <td>40.69</td>\n","      <td>42.29</td>\n","      <td>1707700</td>\n","      <td>45.66</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>45.24</td>\n","      <td>45.83</td>\n","      <td>45.24</td>\n","      <td>45.01</td>\n","      <td>44.69</td>\n","      <td>40.78</td>\n","      <td>42.30</td>\n","      <td>2389800</td>\n","      <td>45.49</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>45.85</td>\n","      <td>46.20</td>\n","      <td>45.48</td>\n","      <td>45.18</td>\n","      <td>44.87</td>\n","      <td>40.87</td>\n","      <td>42.31</td>\n","      <td>3256800</td>\n","      <td>45.21</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>45.38</td>\n","      <td>45.60</td>\n","      <td>45.17</td>\n","      <td>45.27</td>\n","      <td>44.96</td>\n","      <td>40.97</td>\n","      <td>42.31</td>\n","      <td>1955500</td>\n","      <td>44.93</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>45.31</td>\n","      <td>45.44</td>\n","      <td>44.91</td>\n","      <td>45.32</td>\n","      <td>45.04</td>\n","      <td>41.06</td>\n","      <td>42.32</td>\n","      <td>2211100</td>\n","      <td>44.83</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   day  open_price  ...   volume  next_day_close_price\n","0    1       44.55  ...  1500700                 44.83\n","1    2       44.89  ...  2391800                 45.03\n","2    3       45.04  ...  1723400                 44.97\n","3    4       45.02  ...  1490500                 44.91\n","4    5       44.75  ...  1349500                 45.31\n","5    6       45.04  ...  1707700                 45.66\n","6    7       45.24  ...  2389800                 45.49\n","7    8       45.85  ...  3256800                 45.21\n","8    9       45.38  ...  1955500                 44.93\n","9   10       45.31  ...  2211100                 44.83\n","\n","[10 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"MMDnjvBUbDPm","executionInfo":{"status":"ok","timestamp":1623039327972,"user_tz":420,"elapsed":614,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}}},"source":["ngram_polarity = {}\n","for row in df_lexicon.itertuples():\n","  ngram = str(row.ngram)\n","  ngram_polarity[ngram] = row.polarity"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eQEtVuPNfa3","executionInfo":{"status":"ok","timestamp":1623039327979,"user_tz":420,"elapsed":18,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}}},"source":["#define a function that will use the lexicon-based n-gram polarities to compute a \n","#polarity score between -1.0 and +1.0 for the input text.\n","def get_lexicon_polarity(raw_text):\n","  #define a variable to hold a running total of polarity scores\n","  polarity = 0.0\n","  raw_text = str(raw_text)\n","  #define a variable to hold the total number of times n-grams in the polarity\n","  #dictionary appeared in the input text\n","  total_ngram_matches = 0\n","  #convert the input text to lowercase (since all of the n-grams in the polarity\n","  #dictionary are in lowercase)\n","  text = raw_text.lower()\n","  #tokenize the input text\n","  tokens = word_tokenize(text)\n","  #construct a list containing all of the bigrams in the input text\n","  bigrams = []\n","  for i in range(1, len(tokens)):\n","    bigrams.append(tokens[i - 1] + ' ' + tokens[i]) #build all bigrams\n","  #compute running polarity sum and number of n-gram matches\n","  for bigram in bigrams:\n","    #if this bigram appears in the polarity dictionary\n","    if bigram in ngram_polarity:\n","      polarity += ngram_polarity[bigram] #update running total\n","      total_ngram_matches += 1 #update number of n-gram matches\n","    else: #if this bigram does not appear in the polarity dictionary\n","      left_unigram = bigram.split()[0] #get the unigram on the left side of the bigram\n","      #if this unigram appears in the polarity dictionary\n","      if left_unigram in ngram_polarity:\n","        polarity += ngram_polarity[left_unigram] #update running total\n","        total_ngram_matches += 1 #update number of n-gram matches\n","  #compute the overall average polarity score for the input text\n","  if total_ngram_matches == 0 :\n","    polarity = 0\n","  else:\n","    polarity = polarity / total_ngram_matches\n","  #return the polarity score\n","  return polarity"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJMISX7Jch0m","executionInfo":{"status":"ok","timestamp":1623039327980,"user_tz":420,"elapsed":16,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}},"outputId":"32237804-3fc2-48b8-91b1-90a420177902"},"source":["print(df_Tweets.tweet[1111])\n","get_lexicon_polarity('How #Dan is upgrading its #healthy, #eco-friendly assortment via @FortuneMagazine $Dan #retail')"],"execution_count":103,"outputs":[{"output_type":"stream","text":["Strength in retailers? Macy's, Urban Outfitters, GameStop, Best Buy, Dan all higher. top Dow performer. $Dan\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.045688816043126496"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ki3ZXAfOBvx","executionInfo":{"status":"ok","timestamp":1623039349510,"user_tz":420,"elapsed":21541,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}},"outputId":"ab14d61b-2151-4623-ab0b-9f15caabac56"},"source":["#compute lexicon-based polarity scores for each review\n","lexicon_polarities = []\n","for text in df_Tweets.tweet:\n","  lexicon_polarities.append(get_lexicon_polarity(text))\n","  #print(get_lexicon_polarity(text), text)\n","#add lexicon-based polarity scores to the dataframe\n","df_Tweets['lexicon_polarity'] = lexicon_polarities\n","\n","#display the first 10 rows in the dataframe\n","df.head(10)\n","daily_means = df_Tweets[['day','lexicon_polarity']].groupby('day').mean()\n","print(daily_means)"],"execution_count":104,"outputs":[{"output_type":"stream","text":["      lexicon_polarity\n","day                   \n","1            -0.000344\n","2             0.004896\n","3            -0.002235\n","4            -0.015836\n","5             0.004158\n","...                ...\n","1296         -0.001144\n","1297         -0.001867\n","1298          0.015590\n","1299          0.011776\n","1300          0.008727\n","\n","[1300 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5nrFwaUYN-3s","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1623039407801,"user_tz":420,"elapsed":120,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}},"outputId":"c3ab86b9-059e-470c-cacb-58c2c03a4930"},"source":["df['tweet_score'] = daily_means.lexicon_polarity.to_list()\n","#create a dataframe containing only those rows for which\n","#predictions for the next day’s closing price need to be made\n","df_predict = df[pd.isnull(df.next_day_close_price) == True].copy()\n","#remove all incomplete rows from the 'df' dataframe\n","df = df[pd.isnull(df.next_day_close_price) == False].copy()"],"execution_count":106,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-106-22f81456e185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdaily_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon_polarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#create a dataframe containing only those rows for which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#predictions for the next day’s closing price need to be made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_day_close_price\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#remove all incomplete rows from the 'df' dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length of values (1300) does not match length of index (1000)"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"rmzNkNVpsEnR","executionInfo":{"status":"error","timestamp":1623040828159,"user_tz":420,"elapsed":118,"user":{"displayName":"Sean Connolly","photoUrl":"","userId":"15606364408941710004"}},"outputId":"73620923-aa49-450d-f947-d9ff00f70033"},"source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","model = LinearRegression()\n","\n","X = df[['day','open_price','high_price','low_price','moving_average_5_day','moving_average_10_day','moving_average_50_day','moving_average_200_day','volume','tweet_score']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n","Y = df['next_day_close_price']\n","\n","# with sklearn\n","\n","model.fit(X, Y)\n","\n","print('Intercept: \\n', model.intercept_)\n","print('Coefficients: \\n', model.coef_)\n","\n","Z = df_predict[['day','open_price','high_price','low_price','moving_average_5_day','moving_average_10_day','moving_average_50_day','moving_average_200_day','volume','tweet_score']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n","M = df_predict['next_day_close_price']\n","\n","model.predict(Z,M)\n","\n","#df_predict[['day', 'next_day_close_price']].to_csv('Connolly, Sean.csv', index=False)"],"execution_count":113,"outputs":[{"output_type":"stream","text":["Intercept: \n"," 0.4373225845477222\n","Coefficients: \n"," [ 3.33902027e-04 -4.28731622e-01  6.73370129e-01  7.91183301e-01\n"," -4.57919072e-02 -1.74484928e-02  2.05854333e-02 -6.64296296e-03\n","  4.52866178e-08  2.64924489e+01]\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-113-96424aea258f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_day_close_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#df_predict[['day', 'next_day_close_price']].to_csv('Connolly, Sean.csv', index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"]}]}]}